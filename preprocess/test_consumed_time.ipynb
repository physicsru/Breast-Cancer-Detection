{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, json, glob, sys, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import scipy.ndimage\n",
    "\n",
    "sys.path.append('./utils/')\n",
    "from rfdata import RFdata\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MOUNT_PATH = \"/run/user/1000/gvfs/smb-share:server=azlab-fs01,share=東研究室/個人work/富井/\"\n",
    "dir_dataset = MOUNT_PATH + \"PYUSCT_train/dataset008/\"\n",
    "MODEL_PATH = MOUNT_PATH + \"PYUSCT_train/dataset008/ml_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mclf_GPC_rbf_iso.pkl\u001b[0m*              \u001b[01;32mPCA_model.pickle\u001b[0m*\r\n",
      "\u001b[01;32mclf_GPC_rbf_iso_t100_r128.pkl\u001b[0m*    \u001b[01;32mPCA_model_reduced_t100_r128.pickle\u001b[0m*\r\n",
      "\u001b[01;32mclf_GPC_rbf_iso_t100_r64.pkl\u001b[0m*     \u001b[01;32mPCA_model_reduced_t100_r64.pickle\u001b[0m*\r\n",
      "\u001b[01;32mclf_GPC_rbf_iso_T4_t100_r64.pkl\u001b[0m*  \u001b[01;32mPCA_model_reduced_T4_t100_r64.pickle\u001b[0m*\r\n",
      "\u001b[01;32mclf_GPC_rbf_iso_T8_t100_r64.pkl\u001b[0m*  \u001b[01;32mPCA_model_reduced_T8_t100_r64.pickle\u001b[0m*\r\n",
      "\u001b[01;32mclf_GPC_rbf_iso_time100.pkl\u001b[0m*      \u001b[01;32mPCA_model_reduced_time100.pickle\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls $MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = {\n",
    "    \"input\": {\n",
    "        \"sim_path\" : os.path.join(MOUNT_PATH, \"nb_usctsim/sim_005/\"), \n",
    "        \"model_path\" : os.path.join(MOUNT_PATH, \"PYUSCT_train/dataset008/ml_model/PCA_model.pickle\"),\n",
    "        \"size\" : [512, 512],\n",
    "        \"offset\" : [256, 256],\n",
    "        \"interval\": [1,1,1] # Transducer, receiver, time\n",
    "    },\n",
    "    \n",
    "    \"output\" : {\n",
    "        \"path\" : os.path.join(MOUNT_PATH, \"PYUSCT_train/dataset013/\"),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_001\n",
      "trial_002\n",
      "trial_003\n",
      "trial_004\n",
      "trial_005\n",
      "trial_006\n",
      "trial_007\n",
      "trial_008\n",
      "trial_009\n",
      "trial_010\n"
     ]
    }
   ],
   "source": [
    "sim_result_dirs = glob.glob(os.path.join(p[\"input\"][\"sim_path\"], \"trial*\"))\n",
    "sim_result_dirs.sort()\n",
    "for sim_result_dir in sim_result_dirs:\n",
    "    tmp = sim_result_dir.split(\"/\")\n",
    "    print(tmp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_from_sim_to_pca_1m1(fid, input_path, output_path, model_path, indices, interval):\n",
    "    import numpy as np\n",
    "    import string\n",
    "    import os, json, glob, sys, time\n",
    "    sys.path.append('utils/')\n",
    "    from rfdata import RFdata\n",
    "\n",
    "    sfid = str(fid).zfill(3)\n",
    "    \n",
    "    print(\"{}  Thread {}: start\".format(time.ctime(), sfid))\n",
    "    \n",
    "    ## Initial RFdata\n",
    "    rf = RFdata(input_path)\n",
    "    print(\"raw data loaded.\")\n",
    "\n",
    "    ## Load model\n",
    "    from sklearn.externals import joblib\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = joblib.load(model_path) \n",
    "    print(\"Thread {}: PCA model loaded.\".format(sfid))\n",
    "\n",
    "\n",
    "    \n",
    "    ## Define transfer function\n",
    "    def dimension_reduce_rf_point(pca, rf, ix, iy):\n",
    "        offsets = np.arange(-100, 100, interval[2])\n",
    "        _, subset = rf.getPointSubset((ix,iy), offsets)\n",
    "        # have to be a parameter\n",
    "        return pca.transform(subset[::interval[0],::interval[1],:].reshape(1, -1))\n",
    "\n",
    "    \n",
    "    \n",
    "    res = np.empty((len(indices), 800))\n",
    "    cnt = 0;\n",
    "    print(\"Thread {}: processing\".format(sfid))\n",
    "    for (ix, iy) in indices:\n",
    "        res[cnt] = dimension_reduce_rf_point(pca, rf, ix, iy)\n",
    "        cnt += 1\n",
    "        if (cnt % 1000 == 0):\n",
    "            print(\"Thread {}: {} points completes {}\".format(sfid, cnt, time.ctime()))\n",
    "        if (cnt % 2000 == 0):\n",
    "            return\n",
    "    \n",
    "    print(\"Thread {}: Saving file.\".format(sfid))\n",
    "    np.save(output_path + \"part{}_size{}.npy\".format(sfid, cnt), res)\n",
    "    print(\"Thread {}: File saved.\".format(sfid))\n",
    "    \n",
    "    print(\"{}  Thread {}: completed.\".format(time.ctime(), sfid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_raw_1m1_trial_4thread(trial_id, input_path, model_path, output_path, size, offset, interval):\n",
    "    #trial_id = sys.argv[1]\n",
    "    print(\"{} Process of {} start.\".format(time.ctime(), trial_id)) \n",
    "\n",
    "    # debug\n",
    "    print(input_path)\n",
    "    print(output_path)\n",
    "    print(model_path)\n",
    "    \n",
    "    # create indices\n",
    "    indices = np.indices((size[0],size[1]))\n",
    "    indices[0] += offset[0]\n",
    "    indices[1] += offset[1]\n",
    "    indices = indices.transpose(1,2,0)\n",
    "    indices = indices.reshape(-1, 2)      \n",
    "    \n",
    "\n",
    "    # multiply threads\n",
    "    import threading\n",
    "    batch_size = size[0] * size[1] // 4\n",
    "\n",
    "    class myThread (threading.Thread):\n",
    "        def __init__(self, threadID, input_path, output_path, model_path, indices, interval):\n",
    "            threading.Thread.__init__(self)\n",
    "            self.threadID = threadID\n",
    "            self.input_path = input_path\n",
    "            self.output_path = output_path\n",
    "            self.model_path = model_path\n",
    "            self.indices = indices\n",
    "            self.interval = interval\n",
    "        def run(self):\n",
    "            batch_from_sim_to_pca_1m1(self.threadID,\n",
    "                                      self.input_path,\n",
    "                                      self.output_path,\n",
    "                                      self.model_path,\n",
    "                                      self.indices,\n",
    "                                      self.interval,\n",
    "                                     )\n",
    "\n",
    "    thread1 = myThread(0, input_path, output_path, model_path, indices[:batch_size], interval)\n",
    "    thread2 = myThread(1, input_path, output_path, model_path, indices[batch_size:batch_size*2], interval)\n",
    "    thread3 = myThread(2, input_path, output_path, model_path, indices[batch_size*2:batch_size*3], interval)\n",
    "    thread4 = myThread(3, input_path, output_path, model_path, indices[batch_size*3:batch_size*4], interval)\n",
    "\n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    thread3.start()\n",
    "    thread4.start()\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    thread3.join()\n",
    "    thread4.join()\n",
    "\n",
    "    print(\"Exiting Main Thread\")\n",
    "          \n",
    "    print(\"{} Process of {} completed.\".format(time.ctime(), trial_id))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_list = [\".pickle\", \"_reduced_time100.pickle\", \"_reduced_t100_r128.pickle\", \"_reduced_t100_r64.pickle\", \"reduced_T8_t100_r64.pickle\", \"reduced_T4_t100_r64.pickle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  1 12:43:36 2018 Process of trial_001 start.\n",
      "/run/user/1000/gvfs/smb-share:server=azlab-fs01,share=東研究室/個人work/富井/nb_usctsim/sim_005/trial_001\n",
      "/run/user/1000/gvfs/smb-share:server=azlab-fs01,share=東研究室/個人work/富井/PYUSCT_train/dataset013/trial_001/input\n",
      "/run/user/1000/gvfs/smb-share:server=azlab-fs01,share=東研究室/個人work/富井/PYUSCT_train/dataset008/ml_model/PCA_model.pickle\n",
      "Tue May  1 12:43:36 2018  Thread 000: startTue May  1 12:43:36 2018  Thread 001: startTue May  1 12:43:36 2018  Thread 002: start\n",
      "\n",
      "Tue May  1 12:43:36 2018  Thread 003: start\n",
      "\n",
      "raw data loaded.\n",
      "raw data loaded.\n",
      "raw data loaded.\n",
      "raw data loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/sklearn/base.py:312: UserWarning: Trying to unpickle estimator PCA from version 0.18.1 when using version 0.19.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 003: PCA model loaded.\n",
      "Thread 003: processing\n",
      "Thread 001: PCA model loaded.\n",
      "Thread 001: processing\n",
      "Thread 000: PCA model loaded.\n",
      "Thread 000: processing\n",
      "Thread 002: PCA model loaded.\n",
      "Thread 002: processing\n",
      "Thread 002: 1000 points completes Tue May  1 13:08:42 2018\n",
      "Thread 001: 1000 points completes Tue May  1 13:08:49 2018\n",
      "Thread 003: 1000 points completes Tue May  1 13:08:51 2018\n",
      "Thread 000: 1000 points completes Tue May  1 13:09:27 2018\n",
      "Thread 002: 2000 points completes Tue May  1 13:25:09 2018\n",
      "Thread 003: 2000 points completes Tue May  1 13:25:22 2018\n",
      "Thread 001: 2000 points completes Tue May  1 13:25:25 2018\n",
      "Thread 000: 2000 points completes Tue May  1 13:25:40 2018Exiting Main Thread\n",
      "\n",
      "Tue May  1 13:25:40 2018 Process of trial_001 completed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sim_result_dir in sim_result_dirs:\n",
    "    # mkdir for output\n",
    "    trial_id = sim_result_dir.split(\"/\")[-1]\n",
    "    out_dir = os.path.join(p[\"output\"][\"path\"], trial_id)\n",
    "    if not os.path.exists(out_dir): \n",
    "        os.makedirs(os.path.join(out_dir, \"input\"))   # 入力データ\n",
    "        os.makedirs(os.path.join(out_dir, \"output\"))  # 出力データ      \n",
    "        os.makedirs(os.path.join(out_dir, \"sa\"))      # 参照用SA\n",
    "    # save dataX\n",
    "    ## TODO\n",
    "    preprocess_raw_1m1_trial_4thread(trial_id,\n",
    "                                     sim_result_dir, \n",
    "                                     p[\"input\"][\"model_path\"],\n",
    "                                     os.path.join(out_dir, \"input\"),\n",
    "                                     p[\"input\"][\"size\"],\n",
    "                                     p[\"input\"][\"offset\"],\n",
    "                                     p[\"input\"][\"interval\"],\n",
    "                                    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
