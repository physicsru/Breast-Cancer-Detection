{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, time\n",
    "sys.path.append(\"../pyusct/\")\n",
    "from trainer import Trainer_3d_VGG_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "LOCAL_PATH = \"/mnt/nas/\"\n",
    "MODEL_DIR = os.path.join(LOCAL_PATH, \"PYUSCT_model/\")\n",
    "DATA_DIR = os.path.join(LOCAL_PATH, \"PYUSCT_train/\")\n",
    "dataset_dir = os.path.join(DATA_DIR, \"dataset041/\")\n",
    "model_output_path = os.path.join(MODEL_DIR, \"clf/deep/\")\n",
    "scaler_path = os.path.join(MODEL_DIR, \"Scaler/Log_MinMax_RFScaler_ds028.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer_3d_VGG_parallel(dataset_dir, scaler_path, model_output_path, epochs=10, l2_alpha=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nas/PYUSCT_model/clf/deep/20181002-053119/\n"
     ]
    }
   ],
   "source": [
    "print(trainer.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Epoch: 0 Iter 9 Loss: 0.2652343809604645 Time: 1.1203176975250244\n",
      "Epoch: 0 Iter 19 Loss: 0.22676819562911987 Time: 1.1095356941223145\n",
      "Epoch: 0 Iter 29 Loss: 0.5016574263572693 Time: 1.1153392791748047\n",
      "Epoch: 0 Iter 39 Loss: 0.5424937009811401 Time: 1.122990369796753\n",
      "Epoch: 0 Iter 49 Loss: 0.28056278824806213 Time: 1.1185743808746338\n",
      "Epoch: 0 Iter 59 Loss: 0.23992249369621277 Time: 1.1217293739318848\n",
      "Epoch: 0 Iter 69 Loss: 0.5764297246932983 Time: 1.1123063564300537\n",
      "Epoch: 0 Iter 79 Loss: 0.34420937299728394 Time: 1.1363110542297363\n",
      "Epoch: 0 Iter 89 Loss: 0.5848678946495056 Time: 1.1948859691619873\n",
      "Epoch: 0 Iter 99 Loss: 0.6203490495681763 Time: 1.148486614227295\n",
      "Epoch: 0 Iter 109 Loss: 0.5652774572372437 Time: 1.1376590728759766\n",
      "Epoch: 0 Iter 119 Loss: 0.23785856366157532 Time: 1.1842596530914307\n",
      "Epoch: 0 Iter 129 Loss: 0.26707255840301514 Time: 1.1662898063659668\n",
      "Epoch: 0 Iter 139 Loss: 0.31723877787590027 Time: 1.1697850227355957\n",
      "Epoch: 0 Iter 149 Loss: 0.5596616864204407 Time: 1.195284366607666\n",
      "Epoch: 0 Iter 159 Loss: 0.46679025888442993 Time: 1.1856846809387207\n",
      "Epoch: 0 Iter 169 Loss: 0.5727519989013672 Time: 1.1997783184051514\n",
      "Epoch: 0 Iter 179 Loss: 0.4139096736907959 Time: 1.1892457008361816\n",
      "Epoch: 0 Iter 189 Loss: 0.12674739956855774 Time: 1.1804916858673096\n",
      "Epoch: 0 Iter 199 Loss: 0.5744659304618835 Time: 1.1912076473236084\n",
      "Epoch: 0 Iter 209 Loss: 0.47485172748565674 Time: 1.191786289215088\n",
      "Epoch: 0 Iter 219 Loss: 0.4583171606063843 Time: 1.1851584911346436\n",
      "Epoch: 0 Iter 229 Loss: 0.2063627690076828 Time: 1.1941194534301758\n",
      "Epoch: 0 Iter 239 Loss: 0.654805064201355 Time: 1.180326223373413\n",
      "Epoch: 0 Iter 249 Loss: 0.3012423813343048 Time: 1.185183048248291\n",
      "Epoch: 0 Iter 259 Loss: 0.31376340985298157 Time: 1.1871681213378906\n",
      "Epoch: 0 Iter 269 Loss: 0.272545725107193 Time: 1.1856906414031982\n",
      "Epoch: 0 Iter 279 Loss: 0.8475131988525391 Time: 1.1884996891021729\n",
      "Epoch: 0 Iter 289 Loss: 0.11741664260625839 Time: 1.187488317489624\n",
      "Epoch: 0 Iter 299 Loss: 0.44903671741485596 Time: 1.1868183612823486\n",
      "Epoch: 0 Iter 309 Loss: 0.28388866782188416 Time: 1.18902587890625\n",
      "Epoch: 0 Iter 319 Loss: 0.37265652418136597 Time: 1.1889293193817139\n",
      "Epoch: 0 Iter 329 Loss: 0.4944458305835724 Time: 1.1715962886810303\n",
      "Epoch: 0 Iter 339 Loss: 0.35038310289382935 Time: 1.1957085132598877\n",
      "Epoch: 0 Iter 349 Loss: 0.29301363229751587 Time: 1.1877989768981934\n",
      "Epoch: 0 Iter 359 Loss: 0.302174836397171 Time: 1.1945304870605469\n",
      "Epoch: 0 Iter 369 Loss: 0.4123609662055969 Time: 1.1831367015838623\n",
      "Epoch: 0 Iter 379 Loss: 0.4157848060131073 Time: 1.1936290264129639\n",
      "Epoch: 0 Iter 389 Loss: 0.7153698205947876 Time: 1.1910107135772705\n",
      "Epoch: 0 Iter 399 Loss: 0.3178696632385254 Time: 1.1906325817108154\n",
      "Epoch: 0 Iter 409 Loss: 0.18882015347480774 Time: 1.1841225624084473\n",
      "Epoch: 0 Iter 419 Loss: 0.25705426931381226 Time: 1.1967058181762695\n",
      "Epoch: 0 Iter 429 Loss: 0.2372758686542511 Time: 1.2040646076202393\n",
      "Epoch: 0 Iter 439 Loss: 0.4704347252845764 Time: 1.1895954608917236\n",
      "Epoch: 0 Iter 449 Loss: 0.3268488645553589 Time: 1.1919708251953125\n",
      "Epoch: 0 Iter 459 Loss: 0.3553229570388794 Time: 1.199920654296875\n",
      "Epoch: 0 Iter 469 Loss: 0.5781773328781128 Time: 1.191725492477417\n",
      "Epoch: 0 Iter 479 Loss: 0.5903710126876831 Time: 1.1901674270629883\n",
      "Epoch: 0 Iter 489 Loss: 0.5597488284111023 Time: 1.200855016708374\n",
      "Epoch: 0 Iter 499 Loss: 0.5104126334190369 Time: 1.1934142112731934\n",
      "Epoch: 0 Iter 509 Loss: 0.13426417112350464 Time: 1.1830494403839111\n",
      "Epoch: 0 Iter 519 Loss: 0.49304965138435364 Time: 1.195343017578125\n",
      "Epoch: 0 Iter 529 Loss: 0.3291440010070801 Time: 1.2005975246429443\n",
      "Epoch: 0 Iter 539 Loss: 0.16845519840717316 Time: 1.1790704727172852\n",
      "Epoch: 0 Iter 549 Loss: 0.38726580142974854 Time: 1.1990060806274414\n",
      "Epoch: 0 Iter 559 Loss: 0.4510049521923065 Time: 1.1860134601593018\n",
      "Epoch: 0 Iter 569 Loss: 0.47525307536125183 Time: 1.1915862560272217\n",
      "Epoch: 0 Iter 579 Loss: 0.5267305970191956 Time: 1.1990642547607422\n",
      "Epoch: 0 Iter 589 Loss: 0.24993880093097687 Time: 1.1836628913879395\n",
      "Epoch: 0 Iter 599 Loss: 0.5435023307800293 Time: 1.1873588562011719\n",
      "Epoch: 0 Iter 609 Loss: 0.8654096126556396 Time: 1.1885762214660645\n",
      "Epoch: 0 Iter 619 Loss: 0.38620662689208984 Time: 1.1907072067260742\n",
      "Epoch: 0 Iter 629 Loss: 0.3728100061416626 Time: 1.1773998737335205\n",
      "Epoch: 0 Iter 639 Loss: 0.25929683446884155 Time: 1.185924768447876\n",
      "Epoch: 0 Iter 649 Loss: 0.4586644768714905 Time: 1.1899151802062988\n",
      "Epoch: 0 Iter 659 Loss: 0.12924259901046753 Time: 1.196702480316162\n",
      "Epoch: 0 Iter 669 Loss: 0.25604677200317383 Time: 1.1904690265655518\n",
      "Epoch: 0 Iter 679 Loss: 0.8643268346786499 Time: 1.1769180297851562\n",
      "Epoch: 0 Iter 689 Loss: 0.275607705116272 Time: 1.1906490325927734\n",
      "Epoch: 0 Iter 699 Loss: 0.355773001909256 Time: 1.1832482814788818\n",
      "Epoch: 0 Iter 709 Loss: 0.3527902662754059 Time: 1.1988904476165771\n",
      "Epoch: 0 Iter 719 Loss: 0.573168933391571 Time: 1.1834139823913574\n",
      "Epoch: 0 Iter 729 Loss: 0.4649173617362976 Time: 1.184009075164795\n",
      "Epoch: 0 Iter 739 Loss: 0.21066157519817352 Time: 1.187757968902588\n",
      "Epoch: 0 Iter 749 Loss: 0.44496801495552063 Time: 1.1917321681976318\n",
      "Epoch: 0 Iter 759 Loss: 0.39761340618133545 Time: 1.194131851196289\n",
      "Epoch: 0 Iter 769 Loss: 0.22053162753582 Time: 1.1918020248413086\n",
      "Epoch: 0 Iter 779 Loss: 0.2806150019168854 Time: 1.1915457248687744\n",
      "Epoch: 0 Iter 789 Loss: 0.726098358631134 Time: 1.1929559707641602\n",
      "Epoch: 0 Iter 799 Loss: 0.45892566442489624 Time: 1.1848325729370117\n",
      "Epoch: 0 Iter 809 Loss: 0.4194833040237427 Time: 1.1959834098815918\n",
      "Epoch: 0 Iter 819 Loss: 0.26273849606513977 Time: 1.197504997253418\n",
      "Epoch: 0 Iter 829 Loss: 0.2789337635040283 Time: 1.194387674331665\n",
      "Epoch: 0 Iter 839 Loss: 0.2713575065135956 Time: 1.1811168193817139\n",
      "Epoch: 0 Iter 849 Loss: 0.2789146602153778 Time: 1.1931452751159668\n",
      "Epoch: 0 Iter 859 Loss: 0.46149393916130066 Time: 1.1850552558898926\n",
      "Epoch: 0 Iter 869 Loss: 0.3376281261444092 Time: 1.2075984477996826\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.plot_learn_curve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
